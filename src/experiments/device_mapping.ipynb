{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.system import read_ir_from_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('; ModuleID = \\'npb-CG-makea_6.cl\\'\\nsource_filename = \"npb-CG-makea_6.cl\"\\ntarget datalayout = \"e-m:o-i64:64-f80:128-n8:16:32:64-S128\"\\ntarget triple = \"x86_64-apple-macosx10.13.0\"\\n\\n; Function Attrs: nounwind ssp uwtable\\ndefine spir_kernel void @makea_6(double* nocapture, double* nocapture readonly, i32* nocapture readonly, i32* nocapture, i32* nocapture readonly, i32, i32) local_unnamed_addr #0 !kernel_arg_addr_space !4 !kernel_arg_access_qual !5 !kernel_arg_type !6 !kernel_arg_base_type !6 !kernel_arg_type_qual !7 {\\n  %8 = tail call i64 @_Z13get_global_idj(i32 0) #2\\n  %9 = trunc i64 %8 to i32\\n  %10 = icmp slt i32 %9, %6\\n  br i1 %10, label %11, label %112\\n\\n; <label>:11:                                     ; preds = %7\\n  %12 = sext i32 %5 to i64\\n  %13 = getelementptr inbounds i32, i32* %4, i64 %12\\n  %14 = icmp sgt i32 %9, 0\\n  %15 = shl i64 %8, 32\\n  %16 = ashr exact i64 %15, 32\\n  br i1 %14, label %17, label %25\\n\\n; <label>:17:                                     ; preds = %11\\n  %18 = getelementptr inbounds i32, i32* %2, i64 %16\\n  %19 = load i32, i32* %18, align 4, !tbaa !8\\n  %20 = add i64 %15, -4294967296\\n  %21 = ashr exact i64 %20, 32\\n  %22 = getelementptr inbounds i32, i32* %13, i64 %21\\n  %23 = load i32, i32* %22, align 4, !tbaa !8\\n  %24 = sub nsw i32 %19, %23\\n  br label %25\\n\\n; <label>:25:                                     ; preds = %11, %17\\n  %26 = phi i32 [ %24, %17 ], [ 0, %11 ]\\n  %27 = add i64 %15, 4294967296\\n  %28 = ashr exact i64 %27, 32\\n  %29 = getelementptr inbounds i32, i32* %2, i64 %28\\n  %30 = load i32, i32* %29, align 4, !tbaa !8\\n  %31 = getelementptr inbounds i32, i32* %13, i64 %16\\n  %32 = load i32, i32* %31, align 4, !tbaa !8\\n  %33 = sub nsw i32 %30, %32\\n  %34 = icmp slt i32 %26, %33\\n  br i1 %34, label %35, label %112\\n\\n; <label>:35:                                     ; preds = %25\\n  %36 = getelementptr inbounds i32, i32* %2, i64 %16\\n  %37 = load i32, i32* %36, align 4, !tbaa !8\\n  %38 = sext i32 %26 to i64\\n  %39 = sext i32 %37 to i64\\n  %40 = sext i32 %33 to i64\\n  %41 = sub nsw i64 %40, %38\\n  %42 = add nsw i64 %40, -1\\n  %43 = sub nsw i64 %42, %38\\n  %44 = and i64 %41, 3\\n  %45 = icmp eq i64 %44, 0\\n  br i1 %45, label %63, label %46\\n\\n; <label>:46:                                     ; preds = %35\\n  br label %47\\n\\n; <label>:47:                                     ; preds = %47, %46\\n  %48 = phi i64 [ %39, %46 ], [ %59, %47 ]\\n  %49 = phi i64 [ %38, %46 ], [ %60, %47 ]\\n  %50 = phi i64 [ %44, %46 ], [ %61, %47 ]\\n  %51 = getelementptr inbounds double, double* %1, i64 %48\\n  %52 = bitcast double* %51 to i64*\\n  %53 = load i64, i64* %52, align 8, !tbaa !12\\n  %54 = getelementptr inbounds double, double* %0, i64 %49\\n  %55 = bitcast double* %54 to i64*\\n  store i64 %53, i64* %55, align 8, !tbaa !12\\n  %56 = getelementptr inbounds i32, i32* %4, i64 %48\\n  %57 = load i32, i32* %56, align 4, !tbaa !8\\n  %58 = getelementptr inbounds i32, i32* %3, i64 %49\\n  store i32 %57, i32* %58, align 4, !tbaa !8\\n  %59 = add nsw i64 %48, 1\\n  %60 = add nsw i64 %49, 1\\n  %61 = add i64 %50, -1\\n  %62 = icmp eq i64 %61, 0\\n  br i1 %62, label %63, label %47, !llvm.loop !14\\n\\n; <label>:63:                                     ; preds = %47, %35\\n  %64 = phi i64 [ %39, %35 ], [ %59, %47 ]\\n  %65 = phi i64 [ %38, %35 ], [ %60, %47 ]\\n  %66 = icmp ult i64 %43, 3\\n  br i1 %66, label %112, label %67\\n\\n; <label>:67:                                     ; preds = %63\\n  br label %68\\n\\n; <label>:68:                                     ; preds = %68, %67\\n  %69 = phi i64 [ %64, %67 ], [ %109, %68 ]\\n  %70 = phi i64 [ %65, %67 ], [ %110, %68 ]\\n  %71 = getelementptr inbounds double, double* %1, i64 %69\\n  %72 = bitcast double* %71 to i64*\\n  %73 = load i64, i64* %72, align 8, !tbaa !12\\n  %74 = getelementptr inbounds double, double* %0, i64 %70\\n  %75 = bitcast double* %74 to i64*\\n  store i64 %73, i64* %75, align 8, !tbaa !12\\n  %76 = getelementptr inbounds i32, i32* %4, i64 %69\\n  %77 = load i32, i32* %76, align 4, !tbaa !8\\n  %78 = getelementptr inbounds i32, i32* %3, i64 %70\\n  store i32 %77, i32* %78, align 4, !tbaa !8\\n  %79 = add nsw i64 %69, 1\\n  %80 = add nsw i64 %70, 1\\n  %81 = getelementptr inbounds double, double* %1, i64 %79\\n  %82 = bitcast double* %81 to i64*\\n  %83 = load i64, i64* %82, align 8, !tbaa !12\\n  %84 = getelementptr inbounds double, double* %0, i64 %80\\n  %85 = bitcast double* %84 to i64*\\n  store i64 %83, i64* %85, align 8, !tbaa !12\\n  %86 = getelementptr inbounds i32, i32* %4, i64 %79\\n  %87 = load i32, i32* %86, align 4, !tbaa !8\\n  %88 = getelementptr inbounds i32, i32* %3, i64 %80\\n  store i32 %87, i32* %88, align 4, !tbaa !8\\n  %89 = add nsw i64 %69, 2\\n  %90 = add nsw i64 %70, 2\\n  %91 = getelementptr inbounds double, double* %1, i64 %89\\n  %92 = bitcast double* %91 to i64*\\n  %93 = load i64, i64* %92, align 8, !tbaa !12\\n  %94 = getelementptr inbounds double, double* %0, i64 %90\\n  %95 = bitcast double* %94 to i64*\\n  store i64 %93, i64* %95, align 8, !tbaa !12\\n  %96 = getelementptr inbounds i32, i32* %4, i64 %89\\n  %97 = load i32, i32* %96, align 4, !tbaa !8\\n  %98 = getelementptr inbounds i32, i32* %3, i64 %90\\n  store i32 %97, i32* %98, align 4, !tbaa !8\\n  %99 = add nsw i64 %69, 3\\n  %100 = add nsw i64 %70, 3\\n  %101 = getelementptr inbounds double, double* %1, i64 %99\\n  %102 = bitcast double* %101 to i64*\\n  %103 = load i64, i64* %102, align 8, !tbaa !12\\n  %104 = getelementptr inbounds double, double* %0, i64 %100\\n  %105 = bitcast double* %104 to i64*\\n  store i64 %103, i64* %105, align 8, !tbaa !12\\n  %106 = getelementptr inbounds i32, i32* %4, i64 %99\\n  %107 = load i32, i32* %106, align 4, !tbaa !8\\n  %108 = getelementptr inbounds i32, i32* %3, i64 %100\\n  store i32 %107, i32* %108, align 4, !tbaa !8\\n  %109 = add nsw i64 %69, 4\\n  %110 = add nsw i64 %70, 4\\n  %111 = icmp eq i64 %110, %40\\n  br i1 %111, label %112, label %68\\n\\n; <label>:112:                                    ; preds = %63, %68, %25, %7\\n  ret void\\n}\\n\\n; Function Attrs: nounwind readnone\\ndeclare i64 @_Z13get_global_idj(i32) local_unnamed_addr #1\\n\\nattributes #0 = { nounwind ssp uwtable \"correctly-rounded-divide-sqrt-fp-math\"=\"false\" \"disable-tail-calls\"=\"false\" \"less-precise-fpmad\"=\"false\" \"no-frame-pointer-elim\"=\"true\" \"no-frame-pointer-elim-non-leaf\" \"no-infs-fp-math\"=\"false\" \"no-jump-tables\"=\"false\" \"no-nans-fp-math\"=\"false\" \"no-signed-zeros-fp-math\"=\"false\" \"no-trapping-math\"=\"false\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"penryn\" \"target-features\"=\"+cx16,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87\" \"unsafe-fp-math\"=\"false\" \"use-soft-float\"=\"false\" }\\nattributes #1 = { nounwind readnone \"correctly-rounded-divide-sqrt-fp-math\"=\"false\" \"disable-tail-calls\"=\"false\" \"less-precise-fpmad\"=\"false\" \"no-frame-pointer-elim\"=\"true\" \"no-frame-pointer-elim-non-leaf\" \"no-infs-fp-math\"=\"false\" \"no-nans-fp-math\"=\"false\" \"no-signed-zeros-fp-math\"=\"false\" \"no-trapping-math\"=\"false\" \"stack-protector-buffer-size\"=\"8\" \"target-cpu\"=\"penryn\" \"target-features\"=\"+cx16,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87\" \"unsafe-fp-math\"=\"false\" \"use-soft-float\"=\"false\" }\\nattributes #2 = { nounwind readnone }\\n\\n!llvm.module.flags = !{!0, !1}\\n!opencl.ocl.version = !{!2}\\n!llvm.ident = !{!3}\\n\\n!0 = !{i32 1, !\"wchar_size\", i32 4}\\n!1 = !{i32 7, !\"PIC Level\", i32 2}\\n!2 = !{i32 1, i32 0}\\n!3 = !{!\"Apple LLVM version 9.1.0 (clang-902.0.39.1)\"}\\n!4 = !{i32 1, i32 1, i32 1, i32 1, i32 1, i32 0, i32 0}\\n!5 = !{!\"none\", !\"none\", !\"none\", !\"none\", !\"none\", !\"none\", !\"none\"}\\n!6 = !{!\"double*\", !\"double*\", !\"int*\", !\"int*\", !\"int*\", !\"int\", !\"int\"}\\n!7 = !{!\"\", !\"\", !\"\", !\"\", !\"\", !\"\", !\"\"}\\n!8 = !{!9, !9, i64 0}\\n!9 = !{!\"int\", !10, i64 0}\\n!10 = !{!\"omnipotent char\", !11, i64 0}\\n!11 = !{!\"Simple C/C++ TBAA\"}\\n!12 = !{!13, !13, i64 0}\\n!13 = !{!\"double\", !10, i64 0}\\n!14 = distinct !{!14, !15}\\n!15 = !{!\"llvm.loop.unroll.disable\"}\\n',\n",
       " 'CPU',\n",
       " 4.071752,\n",
       " 5.335795)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DevMapDataset(Dataset):\n",
    "    def __init__(self, data_path, platform):\n",
    "        super().__init__()\n",
    "\n",
    "        llfiles = pd.read_csv(data_path + \"/all.txt\", sep=\"\\s+\")\n",
    "        self.fileNum = llfiles[\"FileNum\"]\n",
    "        self.filesname = llfiles[\"ProgramName\"]\n",
    "\n",
    "        self.device_dict = {\"amd\": \"AMD Tahiti 7970\", \"nvidia\": \"NVIDIA GTX 970\"}\n",
    "        self.platform_name = self.device_dict[platform]\n",
    "\n",
    "        # Load runtime data\n",
    "        self.df = pd.read_csv(data_path + \"/cgo17-{}.csv\".format(platform), index_col=0)\n",
    "        self.df[\"bench_data\"] = (\n",
    "            self.df.loc[self.df[\"dataset\"] != \"default\", \"benchmark\"]\n",
    "            + str(\"_\")\n",
    "            + self.df.loc[self.df[\"dataset\"] != \"default\", \"dataset\"]\n",
    "        )\n",
    "        self.df.loc[self.df[\"dataset\"] == \"default\", \"bench_data\"] = self.df.loc[\n",
    "            self.df[\"dataset\"] == \"default\", \"benchmark\"\n",
    "        ]\n",
    "        self.df[\"bench_data_path\"] = data_path + '/kernels_ir/' + self.df[\"bench_data\"] + str(\".ll\")\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        ir = read_ir_from_file(self.df.iloc[index][\"bench_data_path\"])\n",
    "        runtime_cpu = self.df.iloc[index][\"runtime_cpu\"]\n",
    "        runtime_gpu = self.df.iloc[index][\"runtime_gpu\"]\n",
    "        label = self.df.iloc[index][\"oracle\"]\n",
    "        \n",
    "        return ir, label, runtime_cpu, runtime_gpu\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    \n",
    "data_path = '../../data/opencl_device_mapping'\n",
    "dataset = DevMapDataset(data_path, 'nvidia')\n",
    "print(len(dataset))\n",
    "dataset[200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 假设 model 是一个 PyTorch 模型类\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, dense_layer_size):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense_layer = nn.Linear(embedding_dim, dense_layer_size)\n",
    "        self.output_layer = nn.Linear(dense_layer_size, 1)  # 二分类问题输出1个值\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.dense_layer(x))\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "\n",
    "def evaluate(model, device, data_folder, out_folder, embeddings,\n",
    "             dense_layer_size, print_summary, num_epochs, batch_size) -> pd.DataFrame:\n",
    "\n",
    "    # Create device list\n",
    "    if device == 'all':\n",
    "        device_list = [\"amd\", \"nvidia\"]\n",
    "    else:\n",
    "        device_list = [device]\n",
    "\n",
    "    data = []\n",
    "    for i, platform in enumerate(device_list):\n",
    "        platform_name = platform2str(platform)\n",
    "\n",
    "        # Load runtime data\n",
    "        data_file = os.path.join(data_folder, f\"cgo17-{platform}.csv\")\n",
    "        print('\\n--- Read data from', data_file)\n",
    "        df = pd.read_csv(data_file)\n",
    "\n",
    "        # Encode input source codes\n",
    "        sequences, maxlen = encode_srcs(data_folder, df)\n",
    "\n",
    "        # Normalize embeddings using PyTorch\n",
    "        embedding_matrix_normalized = torch.nn.functional.normalize(torch.tensor(embeddings), p=2, dim=1)\n",
    "        sequences_tensor = torch.tensor(sequences, dtype=torch.int64)\n",
    "\n",
    "        embedding_input = embedding_matrix_normalized[sequences_tensor]\n",
    "\n",
    "        # Values used for training & predictions\n",
    "        aux_in = auxiliary_inputs(df)\n",
    "\n",
    "        # Optimal mappings\n",
    "        y = np.array([1 if x == \"GPU\" else 0 for x in df[\"oracle\"].values])\n",
    "        y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "    \n",
    "        # 10-fold cross-validation\n",
    "        n_splits = 10\n",
    "        kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        for j, (train_index, test_index) in enumerate(kf.split(sequences, y)):\n",
    "            print('--- Cross validation step [', j, '/ ', n_splits, ']')\n",
    "\n",
    "            model_name = model.__class__.__name__\n",
    "            model_basename = model_name\n",
    "            model_path = os.path.join(out_folder, f\"models/{model_basename}-{platform}-{j}.model\")\n",
    "            predictions_path = os.path.join(out_folder, f\"predictions/{model_basename}-{platform}-{j}.result\")\n",
    "            log_dir = os.path.join(out_folder, \"logs\")\n",
    "\n",
    "            if os.path.exists(predictions_path):\n",
    "                # load result from cache\n",
    "                print(\"\\tFound predictions in\", predictions_path, \", skipping...\")\n",
    "                with open(predictions_path, 'rb') as infile:\n",
    "                    p = pickle.load(infile)\n",
    "            else:\n",
    "                # Create model and optimizer\n",
    "                model = MyModel(embedding_dim=embedding_matrix_normalized.shape[1], dense_layer_size=dense_layer_size)\n",
    "                optimizer = optim.Adam(model.parameters())\n",
    "                criterion = nn.BCELoss()  # Binary Cross Entropy for binary classification\n",
    "\n",
    "                # Prepare data\n",
    "                train_data = TensorDataset(embedding_input[train_index], y_tensor[train_index])\n",
    "                train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "                if not os.path.exists(model_path):\n",
    "                    # Train model\n",
    "                    print('\\n--- Training model... ')\n",
    "                    for epoch in range(num_epochs):\n",
    "                        model.train()\n",
    "                        total_loss = 0\n",
    "                        for xb, yb in train_loader:\n",
    "                            optimizer.zero_grad()\n",
    "                            output = model(xb)\n",
    "                            loss = criterion(output.view(-1), yb)\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            total_loss += loss.item()\n",
    "\n",
    "                    torch.save(model.state_dict(), model_path)\n",
    "                    print('\\tsaved model to', model_path)\n",
    "\n",
    "                else:\n",
    "                    # Load the saved model\n",
    "                    model.load_state_dict(torch.load(model_path))\n",
    "                    print(\"\\n\\tFound trained model in\", model_path, \", skipping...\")\n",
    "\n",
    "                # Test model\n",
    "                print('\\n--- Testing model... ')\n",
    "                test_data = TensorDataset(embedding_input[test_index], y_tensor[test_index])\n",
    "                test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "                # Predict\n",
    "                model.eval()\n",
    "                p = []\n",
    "                with torch.no_grad():\n",
    "                    for xb, _ in test_loader:\n",
    "                        output = model(xb)\n",
    "                        preds = output.view(-1).round().numpy()\n",
    "                        p.extend(preds)\n",
    "\n",
    "                # Cache results\n",
    "                with open(predictions_path, 'wb') as outfile:\n",
    "                    pickle.dump(p, outfile)\n",
    "                print('\\tsaved predictions to', predictions_path)\n",
    "\n",
    "            # Benchmark names and true values\n",
    "            benchmarks = df['benchmark'].values[test_index]\n",
    "            o = y[test_index]\n",
    "            correct = (np.array(p) == o)\n",
    "\n",
    "            zero_r_dev = \"runtime_cpu\" if platform == \"amd\" else \"runtime_gpu\"\n",
    "            zer_r_runtimes = df[zero_r_dev].values[test_index]\n",
    "            runtimes = df[['runtime_cpu', 'runtime_gpu']].values[test_index]\n",
    "            p_runtimes = [r[p_] for p_, r in zip(np.array(p, dtype=int), runtimes)]\n",
    "            p_speedup = zer_r_runtimes / p_runtimes\n",
    "\n",
    "            assert (len(benchmarks) == len(o) == len(correct) == len(p) == len(p_speedup))\n",
    "\n",
    "            for benchmark_, o_, p_, correct_, p_speedup_ in zip(benchmarks, o, p, correct, p_speedup):\n",
    "                data.append({\n",
    "                    \"Model\": model_basename,\n",
    "                    \"Platform\": platform_name,\n",
    "                    'Benchmark': escape_benchmark_name(benchmark_),\n",
    "                    'Benchmark Suite': escape_suite_name(benchmark_),\n",
    "                    \"Oracle Mapping\": o_,\n",
    "                    \"Predicted Mapping\": p_,\n",
    "                    \"Correct?\": correct_,\n",
    "                    \"Speedup\": p_speedup_,\n",
    "                })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    return pd.DataFrame(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compiler_gym_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
